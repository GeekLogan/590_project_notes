{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from glob import glob\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = glob( '/home/loganaw/sonic_link/590/sliced_out/MET_SUB/*' )\n",
    "random.shuffle( files )\n",
    "\n",
    "train_files = files[:8000]\n",
    "test_files = files[8000:9000]\n",
    "validate_files = files[9000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "files = glob( '/home/loganaw/sonic_link/590/sliced_out/MET/*' )\n",
    "random.shuffle( files )\n",
    "train_files = files[:20000]\n",
    "print( len( train_files ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23618\n"
     ]
    }
   ],
   "source": [
    "train_files = open( 'weighted_sample.txt', 'r').read().splitlines()[:-1]\n",
    "random.shuffle( train_files )\n",
    "print( len( train_files ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "\n",
    "train_data = []\n",
    "train_ans_data = []\n",
    "\n",
    "TILE_SIZE = 64\n",
    "\n",
    "for i,fname in enumerate( train_files ):\n",
    "    f = Image.open(fname)\n",
    "    fi = PIL.ImageOps.invert(f)\n",
    "    fa = np.array( fi, dtype=np.float )\n",
    "    \n",
    "    train_ans_data.append( np.mean( fa[:TILE_SIZE,:TILE_SIZE,:2] ) )\n",
    "    \n",
    "    fa = fa[:TILE_SIZE, 256:256+TILE_SIZE, :]\n",
    "    \n",
    "    for i in range( 3 ):\n",
    "        rge = [ np.min( fa[:,:,i] ), np.max( fa[:,:,i] ) ]\n",
    "        fa[:,:,i] -= rge[0]\n",
    "        fa[:,:,i] /= rge[1]\n",
    "        fa[:,:,i] -= 0.5\n",
    "    \n",
    "    fa = np.moveaxis( fa, 2, 0 )\n",
    "    fa = np.expand_dims(fa, 0)\n",
    "    \n",
    "    train_data.append( torch.tensor( fa ) ) \n",
    "    \n",
    "    f.close()\n",
    "    fi.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "batch_ans_data = []\n",
    "\n",
    "MINI_BATCH = 100 \n",
    "for i in range( 0, 23600, MINI_BATCH ):\n",
    "    batch_data.append( torch.cat( train_data[i:][:MINI_BATCH] ) )\n",
    "    batch_ans_data.append( torch.tensor( train_ans_data[i:][:MINI_BATCH] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ans_data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 4, kernel_size=4, stride=1, padding=2),\n",
    "            BatchNorm2d(4),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            LeakyReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(256, 100),\n",
    "            Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(3, 4, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=100, bias=True)\n",
       "    (1): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1268.850\n",
      "Test = -0.425710529088974 -0.3630094528198242\n",
      "[1,    21] loss: 846.819\n",
      "Test = 10.685508728027344 10.009482383728027\n",
      "[1,    41] loss: 321.612\n",
      "Test = 35.41018295288086 36.701072692871094\n",
      "[1,    61] loss: 341.525\n",
      "Test = 26.764530181884766 28.25602912902832\n",
      "[1,    81] loss: 280.807\n",
      "Test = 31.733196258544922 34.00397872924805\n",
      "[1,   101] loss: 200.474\n",
      "Test = 29.718833923339844 32.3026123046875\n",
      "[1,   121] loss: 251.225\n",
      "Test = 30.443950653076172 33.078365325927734\n",
      "[1,   141] loss: 274.171\n",
      "Test = 31.63004493713379 34.026939392089844\n",
      "[1,   161] loss: 287.607\n",
      "Test = 29.830480575561523 31.935455322265625\n",
      "[1,   181] loss: 288.178\n",
      "Test = 30.895784378051758 33.10701370239258\n",
      "[1,   201] loss: 292.802\n",
      "Test = 29.464391708374023 31.98002052307129\n",
      "[1,   221] loss: 387.971\n",
      "Test = 31.940736770629883 34.76436996459961\n",
      "[2,     1] loss: 279.435\n",
      "Test = 29.86141586303711 32.68475341796875\n",
      "[2,    21] loss: 355.824\n",
      "Test = 31.528175354003906 34.135406494140625\n",
      "[2,    41] loss: 230.996\n",
      "Test = 29.8433895111084 32.457427978515625\n",
      "[2,    61] loss: 324.855\n",
      "Test = 30.390392303466797 33.16689682006836\n",
      "[2,    81] loss: 256.366\n",
      "Test = 30.93861961364746 33.79011154174805\n",
      "[2,   101] loss: 210.798\n",
      "Test = 31.95149040222168 35.16745376586914\n",
      "[2,   121] loss: 238.732\n",
      "Test = 30.336427688598633 33.714168548583984\n",
      "[2,   141] loss: 256.671\n",
      "Test = 32.20077133178711 35.61029815673828\n",
      "[2,   161] loss: 283.320\n",
      "Test = 29.524015426635742 32.671417236328125\n",
      "[2,   181] loss: 288.662\n",
      "Test = 31.182682037353516 34.404911041259766\n",
      "[2,   201] loss: 286.910\n",
      "Test = 29.510272979736328 32.743743896484375\n",
      "[2,   221] loss: 386.581\n",
      "Test = 32.43465805053711 35.85804748535156\n",
      "[3,     1] loss: 275.647\n",
      "Test = 29.974489212036133 33.3394660949707\n",
      "[3,    21] loss: 352.097\n",
      "Test = 31.75688362121582 34.95760726928711\n",
      "[3,    41] loss: 231.639\n",
      "Test = 29.774059295654297 32.9411506652832\n",
      "[3,    61] loss: 327.768\n",
      "Test = 30.701143264770508 33.86913299560547\n",
      "[3,    81] loss: 253.817\n",
      "Test = 31.17311668395996 34.36611557006836\n",
      "[3,   101] loss: 210.393\n",
      "Test = 32.16451644897461 35.6822395324707\n",
      "[3,   121] loss: 237.635\n",
      "Test = 30.888864517211914 34.228118896484375\n",
      "[3,   141] loss: 250.897\n",
      "Test = 32.7684326171875 35.89415740966797\n",
      "[3,   161] loss: 282.635\n",
      "Test = 30.070993423461914 33.0681266784668\n",
      "[3,   181] loss: 284.510\n",
      "Test = 31.655956268310547 34.68952941894531\n",
      "[3,   201] loss: 283.980\n",
      "Test = 30.14621925354004 32.98526382446289\n",
      "[3,   221] loss: 382.440\n",
      "Test = 33.08396911621094 36.204219818115234\n",
      "[4,     1] loss: 272.302\n",
      "Test = 30.715530395507812 33.54927444458008\n",
      "[4,    21] loss: 350.362\n",
      "Test = 32.38151931762695 35.339012145996094\n",
      "[4,    41] loss: 229.540\n",
      "Test = 30.274980545043945 33.22248458862305\n",
      "[4,    61] loss: 327.341\n",
      "Test = 31.293888092041016 34.15647888183594\n",
      "[4,    81] loss: 251.101\n",
      "Test = 31.624984741210938 34.351043701171875\n",
      "[4,   101] loss: 209.294\n",
      "Test = 32.66157913208008 35.66831588745117\n",
      "[4,   121] loss: 237.060\n",
      "Test = 31.368244171142578 34.17325973510742\n",
      "[4,   141] loss: 248.319\n",
      "Test = 33.250877380371094 35.8814697265625\n",
      "[4,   161] loss: 281.509\n",
      "Test = 30.41683006286621 32.97550964355469\n",
      "[4,   181] loss: 281.141\n",
      "Test = 31.92829132080078 34.5238037109375\n",
      "[4,   201] loss: 281.837\n",
      "Test = 30.535493850708008 32.95361328125\n",
      "[4,   221] loss: 381.936\n",
      "Test = 33.32063293457031 36.07926940917969\n",
      "[5,     1] loss: 271.436\n",
      "Test = 30.906333923339844 33.47979736328125\n",
      "[5,    21] loss: 350.145\n",
      "Test = 32.65058135986328 35.55099105834961\n",
      "[5,    41] loss: 228.891\n",
      "Test = 30.35447120666504 33.151065826416016\n",
      "[5,    61] loss: 327.486\n",
      "Test = 31.537227630615234 34.26448059082031\n",
      "[5,    81] loss: 249.233\n",
      "Test = 31.753984451293945 34.2686653137207\n",
      "[5,   101] loss: 208.530\n",
      "Test = 32.88166046142578 35.61674499511719\n",
      "[5,   121] loss: 236.621\n",
      "Test = 31.628658294677734 34.01646423339844\n",
      "[5,   141] loss: 246.372\n",
      "Test = 33.49812316894531 35.75838088989258\n",
      "[5,   161] loss: 281.804\n",
      "Test = 30.57765007019043 32.82642364501953\n",
      "[5,   181] loss: 278.341\n",
      "Test = 32.08786392211914 34.314632415771484\n",
      "[5,   201] loss: 279.595\n",
      "Test = 30.759843826293945 32.793617248535156\n",
      "[5,   221] loss: 381.999\n",
      "Test = 33.37810134887695 35.819374084472656\n",
      "[6,     1] loss: 270.804\n",
      "Test = 30.917346954345703 33.15046310424805\n",
      "[6,    21] loss: 348.876\n",
      "Test = 32.855873107910156 35.424156188964844\n",
      "[6,    41] loss: 228.902\n",
      "Test = 30.396081924438477 32.82938003540039\n",
      "[6,    61] loss: 327.033\n",
      "Test = 31.657285690307617 34.115291595458984\n",
      "[6,    81] loss: 247.721\n",
      "Test = 31.72627067565918 34.00070571899414\n",
      "[6,   101] loss: 208.713\n",
      "Test = 32.911766052246094 35.34443664550781\n",
      "[6,   121] loss: 236.236\n",
      "Test = 31.69948387145996 33.687076568603516\n",
      "[6,   141] loss: 245.121\n",
      "Test = 33.58022689819336 35.41276931762695\n",
      "[6,   161] loss: 281.622\n",
      "Test = 30.573244094848633 32.45097351074219\n",
      "[6,   181] loss: 276.264\n",
      "Test = 32.1105842590332 33.94142150878906\n",
      "[6,   201] loss: 277.677\n",
      "Test = 30.75469207763672 32.45710372924805\n",
      "[6,   221] loss: 382.258\n",
      "Test = 33.35536193847656 35.478607177734375\n",
      "[7,     1] loss: 270.847\n",
      "Test = 30.73821258544922 32.66573715209961\n",
      "[7,    21] loss: 347.474\n",
      "Test = 33.042537689208984 35.163944244384766\n",
      "[7,    41] loss: 229.453\n",
      "Test = 30.38458251953125 32.32892990112305\n",
      "[7,    61] loss: 326.246\n",
      "Test = 31.78730583190918 33.85036087036133\n",
      "[7,    81] loss: 247.018\n",
      "Test = 31.78369903564453 33.696533203125\n",
      "[7,   101] loss: 209.494\n",
      "Test = 33.00025177001953 35.02533721923828\n",
      "[7,   121] loss: 235.987\n",
      "Test = 31.767404556274414 33.33646011352539\n",
      "[7,   141] loss: 243.874\n",
      "Test = 33.65890884399414 35.09450912475586\n",
      "[7,   161] loss: 281.387\n",
      "Test = 30.581560134887695 32.06570053100586\n",
      "[7,   181] loss: 274.332\n",
      "Test = 32.168453216552734 33.61380386352539\n",
      "[7,   201] loss: 276.039\n",
      "Test = 30.806325912475586 32.200111389160156\n",
      "[7,   221] loss: 381.440\n",
      "Test = 33.3751335144043 35.12936019897461\n",
      "[8,     1] loss: 270.802\n",
      "Test = 30.676048278808594 32.36544418334961\n",
      "[8,    21] loss: 346.502\n",
      "Test = 33.16690444946289 34.97394561767578\n",
      "[8,    41] loss: 229.925\n",
      "Test = 30.381555557250977 31.944656372070312\n",
      "[8,    61] loss: 325.850\n",
      "Test = 31.936059951782227 33.6566162109375\n",
      "[8,    81] loss: 246.924\n",
      "Test = 31.819002151489258 33.45661163330078\n",
      "[8,   101] loss: 210.407\n",
      "Test = 33.06671142578125 34.805171966552734\n",
      "[8,   121] loss: 235.833\n",
      "Test = 31.863048553466797 33.11976623535156\n",
      "[8,   141] loss: 243.001\n",
      "Test = 33.75263214111328 34.865478515625\n",
      "[8,   161] loss: 281.277\n",
      "Test = 30.647502899169922 31.78648567199707\n",
      "[8,   181] loss: 272.519\n",
      "Test = 32.25092697143555 33.367088317871094\n",
      "[8,   201] loss: 274.053\n",
      "Test = 30.940452575683594 32.018497467041016\n",
      "[8,   221] loss: 380.583\n",
      "Test = 33.37553405761719 34.83411407470703\n",
      "[9,     1] loss: 271.212\n",
      "Test = 30.678152084350586 32.05207443237305\n",
      "[9,    21] loss: 345.661\n",
      "Test = 33.25507354736328 34.64564895629883\n",
      "[9,    41] loss: 230.022\n",
      "Test = 30.408323287963867 31.582502365112305\n",
      "[9,    61] loss: 324.305\n",
      "Test = 32.01976013183594 33.35470962524414\n",
      "[9,    81] loss: 247.188\n",
      "Test = 31.868545532226562 33.17814636230469\n",
      "[9,   101] loss: 211.282\n",
      "Test = 33.1650390625 34.57943344116211\n",
      "[9,   121] loss: 235.730\n",
      "Test = 31.929201126098633 32.79144287109375\n",
      "[9,   141] loss: 242.043\n",
      "Test = 33.8499870300293 34.53105545043945\n",
      "[9,   161] loss: 280.424\n",
      "Test = 30.711210250854492 31.49570083618164\n",
      "[9,   181] loss: 271.340\n",
      "Test = 32.26507568359375 32.985084533691406\n",
      "[9,   201] loss: 272.552\n",
      "Test = 30.96493911743164 31.549692153930664\n",
      "[9,   221] loss: 379.718\n",
      "Test = 33.41626739501953 34.34010314941406\n",
      "[10,     1] loss: 271.080\n",
      "Test = 30.701045989990234 31.482561111450195\n",
      "[10,    21] loss: 345.165\n",
      "Test = 33.3333740234375 34.07262420654297\n",
      "[10,    41] loss: 229.790\n",
      "Test = 30.36809539794922 31.01993179321289\n",
      "[10,    61] loss: 323.326\n",
      "Test = 32.00639724731445 32.7840576171875\n",
      "[10,    81] loss: 247.391\n",
      "Test = 31.83550453186035 32.54320526123047\n",
      "[10,   101] loss: 212.272\n",
      "Test = 33.25020980834961 34.01408767700195\n",
      "[10,   121] loss: 234.988\n",
      "Test = 31.972938537597656 32.186153411865234\n",
      "[10,   141] loss: 241.123\n",
      "Test = 33.91866683959961 33.90201950073242\n",
      "[10,   161] loss: 280.291\n",
      "Test = 30.737571716308594 30.870677947998047\n",
      "[10,   181] loss: 270.057\n",
      "Test = 32.330596923828125 32.31639099121094\n",
      "[10,   201] loss: 271.129\n",
      "Test = 31.04712677001953 30.935026168823242\n",
      "[10,   221] loss: 378.752\n",
      "Test = 33.40890884399414 33.694549560546875\n",
      "[11,     1] loss: 271.535\n",
      "Test = 30.703632354736328 30.79393196105957\n",
      "[11,    21] loss: 343.966\n",
      "Test = 33.461952209472656 33.5064697265625\n",
      "[11,    41] loss: 230.134\n",
      "Test = 30.393661499023438 30.392053604125977\n",
      "[11,    61] loss: 322.464\n",
      "Test = 32.08924865722656 32.11526870727539\n",
      "[11,    81] loss: 247.774\n",
      "Test = 31.87726402282715 31.895383834838867\n",
      "[11,   101] loss: 213.718\n",
      "Test = 33.322021484375 33.2804069519043\n",
      "[11,   121] loss: 234.382\n",
      "Test = 32.02178955078125 31.48523712158203\n",
      "[11,   141] loss: 240.098\n",
      "Test = 33.994083404541016 33.24473571777344\n",
      "[11,   161] loss: 280.008\n",
      "Test = 30.873720169067383 30.276294708251953\n",
      "[11,   181] loss: 268.302\n",
      "Test = 32.42081069946289 31.581804275512695\n",
      "[11,   201] loss: 269.864\n",
      "Test = 31.278167724609375 30.291030883789062\n",
      "[11,   221] loss: 377.899\n",
      "Test = 33.43814468383789 32.96139144897461\n",
      "[12,     1] loss: 271.753\n",
      "Test = 30.815353393554688 30.09084129333496\n",
      "[12,    21] loss: 343.544\n",
      "Test = 33.54143142700195 32.739166259765625\n",
      "[12,    41] loss: 230.012\n",
      "Test = 30.42780876159668 29.61306381225586\n",
      "[12,    61] loss: 322.014\n",
      "Test = 32.10771942138672 31.34650993347168\n",
      "[12,    81] loss: 247.977\n",
      "Test = 31.921262741088867 31.04471206665039\n",
      "[12,   101] loss: 214.654\n",
      "Test = 33.437774658203125 32.44504928588867\n",
      "[12,   121] loss: 233.862\n",
      "Test = 32.132240295410156 30.632688522338867\n",
      "[12,   141] loss: 239.437\n",
      "Test = 34.1146125793457 32.26772689819336\n",
      "[12,   161] loss: 279.283\n",
      "Test = 31.099620819091797 29.39833641052246\n",
      "[12,   181] loss: 266.930\n",
      "Test = 32.6186408996582 30.657564163208008\n",
      "[12,   201] loss: 267.487\n",
      "Test = 31.599458694458008 29.41329002380371\n",
      "[12,   221] loss: 376.724\n",
      "Test = 33.573204040527344 31.908903121948242\n",
      "[13,     1] loss: 271.781\n",
      "Test = 31.140254974365234 29.24952507019043\n",
      "[13,    21] loss: 343.944\n",
      "Test = 33.70040512084961 31.81732749938965\n",
      "[13,    41] loss: 230.356\n",
      "Test = 30.6036319732666 28.79153823852539\n",
      "[13,    61] loss: 320.689\n",
      "Test = 32.18853759765625 30.568660736083984\n",
      "[13,    81] loss: 248.295\n",
      "Test = 32.12400817871094 30.355998992919922\n",
      "[13,   101] loss: 216.162\n",
      "Test = 33.703338623046875 31.692373275756836\n",
      "[13,   121] loss: 232.557\n",
      "Test = 32.3574104309082 29.82208824157715\n",
      "[13,   141] loss: 238.323\n",
      "Test = 34.2932243347168 31.433080673217773\n",
      "[13,   161] loss: 279.020\n",
      "Test = 31.2687931060791 28.716310501098633\n",
      "[13,   181] loss: 265.581\n",
      "Test = 32.71799850463867 29.867713928222656\n",
      "[13,   201] loss: 265.484\n",
      "Test = 31.832693099975586 28.716060638427734\n",
      "[13,   221] loss: 375.210\n",
      "Test = 33.66840744018555 30.993532180786133\n",
      "[14,     1] loss: 271.227\n",
      "Test = 31.259878158569336 28.442729949951172\n",
      "[14,    21] loss: 344.169\n",
      "Test = 33.81169128417969 31.14851951599121\n",
      "[14,    41] loss: 230.412\n",
      "Test = 30.759517669677734 27.980501174926758\n",
      "[14,    61] loss: 320.219\n",
      "Test = 32.34933853149414 29.856054306030273\n",
      "[14,    81] loss: 248.062\n",
      "Test = 32.26470184326172 29.509918212890625\n",
      "[14,   101] loss: 218.110\n",
      "Test = 33.877540588378906 30.776103973388672\n",
      "[14,   121] loss: 231.509\n",
      "Test = 32.46440124511719 29.00339698791504\n",
      "[14,   141] loss: 236.838\n",
      "Test = 34.4948616027832 30.611209869384766\n",
      "[14,   161] loss: 279.000\n",
      "Test = 31.59083366394043 27.745195388793945\n",
      "[14,   181] loss: 263.922\n",
      "Test = 32.9742317199707 28.894039154052734\n",
      "[14,   201] loss: 263.369\n",
      "Test = 32.17743682861328 27.778902053833008\n",
      "[14,   221] loss: 373.070\n",
      "Test = 33.93672180175781 30.085723876953125\n",
      "[15,     1] loss: 270.617\n",
      "Test = 31.628334045410156 27.503456115722656\n",
      "[15,    21] loss: 344.796\n",
      "Test = 34.300933837890625 30.321382522583008\n",
      "[15,    41] loss: 230.408\n",
      "Test = 30.961265563964844 27.189376831054688\n",
      "[15,    61] loss: 319.121\n",
      "Test = 32.44615936279297 29.027496337890625\n",
      "[15,    81] loss: 248.439\n",
      "Test = 32.564579010009766 28.768373489379883\n",
      "[15,   101] loss: 220.004\n",
      "Test = 34.2996940612793 29.943309783935547\n",
      "[15,   121] loss: 230.589\n",
      "Test = 32.973655700683594 28.078022003173828\n",
      "[15,   141] loss: 233.882\n",
      "Test = 34.968894958496094 29.699522018432617\n",
      "[15,   161] loss: 280.236\n",
      "Test = 32.39634704589844 26.85298728942871\n",
      "[15,   181] loss: 261.802\n",
      "Test = 33.4399528503418 27.803272247314453\n",
      "[15,   201] loss: 260.611\n",
      "Test = 32.8497428894043 27.12983512878418\n",
      "[15,   221] loss: 369.973\n",
      "Test = 34.11623001098633 29.11803436279297\n",
      "[16,     1] loss: 270.269\n",
      "Test = 32.26277160644531 26.639537811279297\n",
      "[16,    21] loss: 345.739\n",
      "Test = 35.00861740112305 29.66857147216797\n",
      "[16,    41] loss: 229.421\n",
      "Test = 31.3399715423584 26.63800811767578\n",
      "[16,    61] loss: 316.236\n",
      "Test = 32.640621185302734 28.242345809936523\n",
      "[16,    81] loss: 248.296\n",
      "Test = 32.94989776611328 28.0009708404541\n",
      "[16,   101] loss: 221.285\n",
      "Test = 34.764286041259766 29.231056213378906\n",
      "[16,   121] loss: 230.328\n",
      "Test = 33.40032196044922 27.45482635498047\n",
      "[16,   141] loss: 232.619\n",
      "Test = 35.3955192565918 29.036420822143555\n",
      "[16,   161] loss: 280.422\n",
      "Test = 33.0816535949707 26.202558517456055\n",
      "[16,   181] loss: 260.383\n",
      "Test = 33.833492279052734 27.013139724731445\n",
      "[16,   201] loss: 259.343\n",
      "Test = 33.56354904174805 26.674556732177734\n",
      "[16,   221] loss: 367.142\n",
      "Test = 34.53752517700195 28.479049682617188\n",
      "[17,     1] loss: 270.114\n",
      "Test = 32.952510833740234 26.105993270874023\n",
      "[17,    21] loss: 346.282\n",
      "Test = 35.43624496459961 28.99559783935547\n",
      "[17,    41] loss: 227.600\n",
      "Test = 31.767404556274414 26.052427291870117\n",
      "[17,    61] loss: 313.959\n",
      "Test = 32.97005844116211 27.654190063476562\n",
      "[17,    81] loss: 247.574\n",
      "Test = 33.427433013916016 27.484806060791016\n",
      "[17,   101] loss: 221.800\n",
      "Test = 35.337608337402344 28.79158592224121\n",
      "[17,   121] loss: 229.442\n",
      "Test = 33.80237579345703 26.916505813598633\n",
      "[17,   141] loss: 230.279\n",
      "Test = 35.981590270996094 28.563459396362305\n",
      "[17,   161] loss: 280.441\n",
      "Test = 33.74849319458008 25.66143798828125\n",
      "[17,   181] loss: 259.620\n",
      "Test = 34.15669631958008 26.620718002319336\n",
      "[17,   201] loss: 257.598\n",
      "Test = 33.91944885253906 26.531415939331055\n",
      "[17,   221] loss: 365.400\n",
      "Test = 34.650001525878906 28.202049255371094\n",
      "[18,     1] loss: 269.987\n",
      "Test = 33.352020263671875 25.80628204345703\n",
      "[18,    21] loss: 346.574\n",
      "Test = 35.74945068359375 28.81893539428711\n",
      "[18,    41] loss: 226.437\n",
      "Test = 32.05072021484375 25.814258575439453\n",
      "[18,    61] loss: 311.417\n",
      "Test = 33.11564254760742 27.08417510986328\n",
      "[18,    81] loss: 247.629\n",
      "Test = 33.732765197753906 26.963430404663086\n",
      "[18,   101] loss: 222.688\n",
      "Test = 35.749515533447266 28.31797218322754\n",
      "[18,   121] loss: 228.144\n",
      "Test = 34.180023193359375 26.28957748413086\n",
      "[18,   141] loss: 229.787\n",
      "Test = 36.50117492675781 28.182106018066406\n",
      "[18,   161] loss: 277.857\n",
      "Test = 34.265254974365234 25.52960777282715\n",
      "[18,   181] loss: 259.425\n",
      "Test = 34.198692321777344 26.511444091796875\n",
      "[18,   201] loss: 257.181\n",
      "Test = 34.2820930480957 26.759611129760742\n",
      "[18,   221] loss: 364.560\n",
      "Test = 34.70378494262695 28.016260147094727\n",
      "[19,     1] loss: 269.936\n",
      "Test = 33.692317962646484 25.77251434326172\n",
      "[19,    21] loss: 345.828\n",
      "Test = 36.01741409301758 28.66880989074707\n",
      "[19,    41] loss: 225.915\n",
      "Test = 32.5124397277832 25.871360778808594\n",
      "[19,    61] loss: 310.224\n",
      "Test = 33.35748291015625 26.9349422454834\n",
      "[19,    81] loss: 246.030\n",
      "Test = 33.95680618286133 26.900693893432617\n",
      "[19,   101] loss: 223.004\n",
      "Test = 35.95790481567383 28.120365142822266\n",
      "[19,   121] loss: 226.910\n",
      "Test = 34.47283935546875 26.243549346923828\n",
      "[19,   141] loss: 229.033\n",
      "Test = 36.983768463134766 28.185007095336914\n",
      "[19,   161] loss: 276.005\n",
      "Test = 34.62607192993164 25.32828140258789\n",
      "[19,   181] loss: 259.056\n",
      "Test = 34.207794189453125 26.345916748046875\n",
      "[19,   201] loss: 255.873\n",
      "Test = 34.31296157836914 26.68766975402832\n",
      "[19,   221] loss: 363.591\n",
      "Test = 34.74757766723633 28.15825653076172\n",
      "[20,     1] loss: 270.096\n",
      "Test = 33.815284729003906 26.04730796813965\n",
      "[20,    21] loss: 344.799\n",
      "Test = 36.29417419433594 28.93566131591797\n",
      "[20,    41] loss: 225.281\n",
      "Test = 32.729827880859375 25.96484375\n",
      "[20,    61] loss: 309.299\n",
      "Test = 33.485076904296875 26.88947296142578\n",
      "[20,    81] loss: 245.240\n",
      "Test = 34.16928482055664 26.762956619262695\n",
      "[20,   101] loss: 223.711\n",
      "Test = 36.10560607910156 27.986087799072266\n",
      "[20,   121] loss: 227.609\n",
      "Test = 34.49726867675781 26.258007049560547\n",
      "[20,   141] loss: 228.621\n",
      "Test = 37.13796615600586 28.37495994567871\n",
      "[20,   161] loss: 276.703\n",
      "Test = 34.65271759033203 25.59745979309082\n",
      "[20,   181] loss: 258.710\n",
      "Test = 34.404239654541016 26.808034896850586\n",
      "[20,   201] loss: 255.550\n",
      "Test = 34.29230880737305 26.846416473388672\n",
      "[20,   221] loss: 363.224\n",
      "Test = 34.777462005615234 28.26038360595703\n",
      "[21,     1] loss: 269.961\n",
      "Test = 33.798301696777344 26.282062530517578\n",
      "[21,    21] loss: 344.133\n",
      "Test = 36.363216400146484 29.04398536682129\n",
      "[21,    41] loss: 224.888\n",
      "Test = 32.756385803222656 25.875328063964844\n",
      "[21,    61] loss: 309.101\n",
      "Test = 33.54035568237305 26.922649383544922\n",
      "[21,    81] loss: 244.725\n",
      "Test = 34.220787048339844 26.695459365844727\n",
      "[21,   101] loss: 223.671\n",
      "Test = 36.224666595458984 27.939645767211914\n",
      "[21,   121] loss: 227.535\n",
      "Test = 34.52790069580078 26.232221603393555\n",
      "[21,   141] loss: 228.097\n",
      "Test = 37.25542068481445 28.377500534057617\n",
      "[21,   161] loss: 274.381\n",
      "Test = 34.751216888427734 25.666034698486328\n",
      "[21,   181] loss: 258.031\n",
      "Test = 34.37320327758789 26.863988876342773\n",
      "[21,   201] loss: 255.718\n",
      "Test = 34.29428482055664 27.029340744018555\n",
      "[21,   221] loss: 363.530\n",
      "Test = 34.82316589355469 28.415950775146484\n",
      "[22,     1] loss: 270.788\n",
      "Test = 33.746376037597656 26.452083587646484\n",
      "[22,    21] loss: 343.471\n",
      "Test = 36.44662857055664 29.239696502685547\n",
      "[22,    41] loss: 224.883\n",
      "Test = 32.715240478515625 26.02406883239746\n",
      "[22,    61] loss: 309.299\n",
      "Test = 33.48187255859375 27.13322639465332\n",
      "[22,    81] loss: 243.916\n",
      "Test = 34.199100494384766 26.850814819335938\n",
      "[22,   101] loss: 223.966\n",
      "Test = 36.11814880371094 28.074440002441406\n",
      "[22,   121] loss: 227.560\n",
      "Test = 34.36729431152344 26.468976974487305\n",
      "[22,   141] loss: 227.469\n",
      "Test = 37.23162078857422 28.640024185180664\n",
      "[22,   161] loss: 273.959\n",
      "Test = 34.66842269897461 26.08670425415039\n",
      "[22,   181] loss: 257.507\n",
      "Test = 34.34789276123047 27.28191375732422\n",
      "[22,   201] loss: 255.009\n",
      "Test = 34.23760986328125 27.392847061157227\n",
      "[22,   221] loss: 362.759\n",
      "Test = 34.916831970214844 28.845796585083008\n",
      "[23,     1] loss: 270.473\n",
      "Test = 33.800052642822266 27.161108016967773\n",
      "[23,    21] loss: 343.499\n",
      "Test = 36.34750747680664 29.617931365966797\n",
      "[23,    41] loss: 224.769\n",
      "Test = 32.79248046875 26.668960571289062\n",
      "[23,    61] loss: 309.578\n",
      "Test = 33.3749885559082 27.556537628173828\n",
      "[23,    81] loss: 243.886\n",
      "Test = 34.27544403076172 27.44605255126953\n",
      "[23,   101] loss: 223.572\n",
      "Test = 36.09262466430664 28.522714614868164\n",
      "[23,   121] loss: 226.853\n",
      "Test = 34.39658737182617 26.902189254760742\n",
      "[23,   141] loss: 226.318\n",
      "Test = 37.33369064331055 28.835920333862305\n",
      "[23,   161] loss: 272.440\n",
      "Test = 34.69318771362305 26.41435432434082\n",
      "[23,   181] loss: 257.704\n",
      "Test = 34.15681838989258 27.50608253479004\n",
      "[23,   201] loss: 256.523\n",
      "Test = 34.251060485839844 28.179704666137695\n",
      "[23,   221] loss: 364.028\n",
      "Test = 35.004669189453125 29.35552406311035\n",
      "[24,     1] loss: 270.822\n",
      "Test = 33.573272705078125 27.463062286376953\n",
      "[24,    21] loss: 341.104\n",
      "Test = 36.219112396240234 30.094038009643555\n",
      "[24,    41] loss: 223.932\n",
      "Test = 32.868133544921875 27.241775512695312\n",
      "[24,    61] loss: 309.479\n",
      "Test = 33.33973693847656 27.871437072753906\n",
      "[24,    81] loss: 243.561\n",
      "Test = 33.962947845458984 27.79688835144043\n",
      "[24,   101] loss: 223.065\n",
      "Test = 35.68181228637695 28.991893768310547\n",
      "[24,   121] loss: 225.597\n",
      "Test = 34.111900329589844 27.428096771240234\n",
      "[24,   141] loss: 225.147\n",
      "Test = 36.99037551879883 29.20963478088379\n",
      "[24,   161] loss: 271.131\n",
      "Test = 34.13774871826172 26.750255584716797\n",
      "[24,   181] loss: 258.366\n",
      "Test = 34.17282485961914 28.0051212310791\n",
      "[24,   201] loss: 259.027\n",
      "Test = 33.879669189453125 28.320858001708984\n",
      "[24,   221] loss: 364.515\n",
      "Test = 35.01371765136719 29.78241539001465\n",
      "[25,     1] loss: 272.535\n",
      "Test = 33.35064697265625 27.639545440673828\n",
      "[25,    21] loss: 340.538\n",
      "Test = 35.93779754638672 30.4783935546875\n",
      "[25,    41] loss: 223.957\n",
      "Test = 32.5842399597168 27.51566505432129\n",
      "[25,    61] loss: 310.659\n",
      "Test = 33.178245544433594 28.22394561767578\n",
      "[25,    81] loss: 242.928\n",
      "Test = 33.744773864746094 28.13038444519043\n",
      "[25,   101] loss: 223.143\n",
      "Test = 35.386783599853516 29.114713668823242\n",
      "[25,   121] loss: 226.236\n",
      "Test = 33.89098358154297 27.579463958740234\n",
      "[25,   141] loss: 223.761\n",
      "Test = 36.771671295166016 29.29929542541504\n",
      "[25,   161] loss: 270.536\n",
      "Test = 33.881187438964844 26.981761932373047\n",
      "[25,   181] loss: 258.148\n",
      "Test = 34.214027404785156 28.419214248657227\n",
      "[25,   201] loss: 259.742\n",
      "Test = 33.76544952392578 28.399276733398438\n",
      "[25,   221] loss: 363.776\n",
      "Test = 35.030643463134766 29.945070266723633\n",
      "[26,     1] loss: 273.601\n",
      "Test = 33.19666290283203 27.686649322509766\n",
      "[26,    21] loss: 338.918\n",
      "Test = 35.78628921508789 30.367877960205078\n",
      "[26,    41] loss: 224.234\n",
      "Test = 32.49333190917969 27.847393035888672\n",
      "[26,    61] loss: 311.972\n",
      "Test = 33.10026550292969 28.389493942260742\n",
      "[26,    81] loss: 242.777\n",
      "Test = 33.69117736816406 28.330854415893555\n",
      "[26,   101] loss: 223.454\n",
      "Test = 35.270320892333984 29.33450698852539\n",
      "[26,   121] loss: 226.139\n",
      "Test = 33.773616790771484 27.936826705932617\n",
      "[26,   141] loss: 222.330\n",
      "Test = 36.62797927856445 29.6905460357666\n",
      "[26,   161] loss: 270.414\n",
      "Test = 33.56414794921875 27.45470428466797\n",
      "[26,   181] loss: 257.493\n",
      "Test = 34.06733703613281 28.751964569091797\n",
      "[26,   201] loss: 262.305\n",
      "Test = 33.57175064086914 28.310440063476562\n",
      "[26,   221] loss: 362.111\n",
      "Test = 34.9804573059082 30.17198944091797\n",
      "[27,     1] loss: 274.750\n",
      "Test = 33.08926010131836 27.884920120239258\n",
      "[27,    21] loss: 339.066\n",
      "Test = 35.90813446044922 30.94148063659668\n",
      "[27,    41] loss: 224.107\n",
      "Test = 32.46767807006836 28.071548461914062\n",
      "[27,    61] loss: 312.920\n",
      "Test = 32.923805236816406 28.51690101623535\n",
      "[27,    81] loss: 243.413\n",
      "Test = 33.456478118896484 28.638864517211914\n",
      "[27,   101] loss: 224.968\n",
      "Test = 34.980777740478516 29.81896209716797\n",
      "[27,   121] loss: 225.907\n",
      "Test = 33.44516372680664 28.301305770874023\n",
      "[27,   141] loss: 221.887\n",
      "Test = 36.235939025878906 30.008127212524414\n",
      "[27,   161] loss: 268.705\n",
      "Test = 33.29258728027344 28.045875549316406\n",
      "[27,   181] loss: 257.549\n",
      "Test = 33.78231430053711 29.32487678527832\n",
      "[27,   201] loss: 260.420\n",
      "Test = 33.124656677246094 28.572433471679688\n",
      "[27,   221] loss: 362.504\n",
      "Test = 34.538963317871094 30.55750846862793\n",
      "[28,     1] loss: 274.401\n",
      "Test = 32.63798141479492 28.155128479003906\n",
      "[28,    21] loss: 337.818\n",
      "Test = 35.3794059753418 31.018783569335938\n",
      "[28,    41] loss: 224.760\n",
      "Test = 32.074363708496094 28.06859588623047\n",
      "[28,    61] loss: 312.670\n",
      "Test = 32.70335006713867 28.646038055419922\n",
      "[28,    81] loss: 243.375\n",
      "Test = 33.06355667114258 28.847639083862305\n",
      "[28,   101] loss: 225.903\n",
      "Test = 34.515098571777344 30.060094833374023\n",
      "[28,   121] loss: 226.096\n",
      "Test = 33.09716033935547 28.52797508239746\n",
      "[28,   141] loss: 221.110\n",
      "Test = 36.03478240966797 30.246227264404297\n",
      "[28,   161] loss: 268.692\n",
      "Test = 33.02335739135742 28.347192764282227\n",
      "[28,   181] loss: 257.780\n",
      "Test = 33.61457061767578 29.72309112548828\n",
      "[28,   201] loss: 258.699\n",
      "Test = 32.78441619873047 29.038490295410156\n",
      "[28,   221] loss: 362.549\n",
      "Test = 34.25074005126953 30.74067497253418\n",
      "[29,     1] loss: 275.025\n",
      "Test = 32.229854583740234 28.186359405517578\n",
      "[29,    21] loss: 337.137\n",
      "Test = 35.03466033935547 30.74324607849121\n",
      "[29,    41] loss: 225.335\n",
      "Test = 31.610591888427734 28.071191787719727\n",
      "[29,    61] loss: 312.265\n",
      "Test = 32.256202697753906 28.676015853881836\n",
      "[29,    81] loss: 243.015\n",
      "Test = 32.59707260131836 28.910057067871094\n",
      "[29,   101] loss: 225.970\n",
      "Test = 34.02742385864258 30.008285522460938\n",
      "[29,   121] loss: 225.974\n",
      "Test = 32.72077178955078 28.711692810058594\n",
      "[29,   141] loss: 220.400\n",
      "Test = 35.76200866699219 30.827909469604492\n",
      "[29,   161] loss: 269.095\n",
      "Test = 32.526634216308594 28.502870559692383\n",
      "[29,   181] loss: 257.358\n",
      "Test = 33.30301284790039 30.05747413635254\n",
      "[29,   201] loss: 261.994\n",
      "Test = 32.426971435546875 29.187623977661133\n",
      "[29,   221] loss: 362.673\n",
      "Test = 34.047306060791016 30.910066604614258\n",
      "[30,     1] loss: 276.402\n",
      "Test = 31.834871292114258 28.062196731567383\n",
      "[30,    21] loss: 336.368\n",
      "Test = 34.68484115600586 30.56682586669922\n",
      "[30,    41] loss: 225.015\n",
      "Test = 31.405818939208984 28.290672302246094\n",
      "[30,    61] loss: 311.271\n",
      "Test = 31.97589111328125 28.75972557067871\n",
      "[30,    81] loss: 242.355\n",
      "Test = 32.326229095458984 28.748144149780273\n",
      "[30,   101] loss: 227.138\n",
      "Test = 33.74482727050781 29.858858108520508\n",
      "[30,   121] loss: 225.825\n",
      "Test = 32.58562088012695 28.59421730041504\n",
      "[30,   141] loss: 219.734\n",
      "Test = 35.54531478881836 30.838525772094727\n",
      "[30,   161] loss: 269.835\n",
      "Test = 32.23516845703125 28.639732360839844\n",
      "[30,   181] loss: 256.761\n",
      "Test = 33.16080856323242 30.167768478393555\n",
      "[30,   201] loss: 263.378\n",
      "Test = 32.345462799072266 29.560394287109375\n",
      "[30,   221] loss: 362.438\n",
      "Test = 33.92265701293945 31.007091522216797\n",
      "[31,     1] loss: 277.011\n",
      "Test = 31.6311092376709 28.164953231811523\n",
      "[31,    21] loss: 334.909\n",
      "Test = 34.219383239746094 30.267229080200195\n",
      "[31,    41] loss: 225.923\n",
      "Test = 31.17371940612793 28.269840240478516\n",
      "[31,    61] loss: 310.204\n",
      "Test = 31.71537208557129 28.929744720458984\n",
      "[31,    81] loss: 241.193\n",
      "Test = 32.01017761230469 28.702770233154297\n",
      "[31,   101] loss: 227.259\n",
      "Test = 33.39980697631836 29.817142486572266\n",
      "[31,   121] loss: 227.775\n",
      "Test = 32.43064880371094 28.75385093688965\n",
      "[31,   141] loss: 220.728\n",
      "Test = 35.290164947509766 31.085227966308594\n",
      "[31,   161] loss: 269.879\n",
      "Test = 32.226280212402344 29.02550506591797\n",
      "[31,   181] loss: 255.827\n",
      "Test = 33.07796859741211 30.4052677154541\n",
      "[31,   201] loss: 259.269\n",
      "Test = 32.27536392211914 29.858015060424805\n",
      "[31,   221] loss: 361.960\n",
      "Test = 33.86457824707031 30.89168357849121\n",
      "[32,     1] loss: 276.748\n",
      "Test = 31.58822250366211 28.049409866333008\n",
      "[32,    21] loss: 338.055\n",
      "Test = 33.9300651550293 29.79829216003418\n",
      "[32,    41] loss: 226.681\n",
      "Test = 30.965679168701172 28.242782592773438\n",
      "[32,    61] loss: 309.353\n",
      "Test = 31.507915496826172 28.87375831604004\n",
      "[32,    81] loss: 241.002\n",
      "Test = 31.795360565185547 28.79128074645996\n",
      "[32,   101] loss: 227.333\n",
      "Test = 32.98484420776367 29.969980239868164\n",
      "[32,   121] loss: 227.925\n",
      "Test = 32.1468391418457 28.7474365234375\n",
      "[32,   141] loss: 221.803\n",
      "Test = 35.027156829833984 31.100887298583984\n",
      "[32,   161] loss: 269.526\n",
      "Test = 31.980905532836914 29.49298095703125\n",
      "[32,   181] loss: 256.631\n",
      "Test = 33.15742874145508 30.921371459960938\n",
      "[32,   201] loss: 259.038\n",
      "Test = 32.14128875732422 30.134544372558594\n",
      "[32,   221] loss: 360.333\n",
      "Test = 33.64415740966797 30.836563110351562\n",
      "[33,     1] loss: 277.472\n",
      "Test = 31.206707000732422 27.96596336364746\n",
      "[33,    21] loss: 339.092\n",
      "Test = 33.60081481933594 29.71303939819336\n",
      "[33,    41] loss: 227.488\n",
      "Test = 30.618331909179688 28.27002716064453\n",
      "[33,    61] loss: 307.192\n",
      "Test = 31.18832015991211 28.997644424438477\n",
      "[33,    81] loss: 240.457\n",
      "Test = 31.548158645629883 29.123905181884766\n",
      "[33,   101] loss: 227.773\n",
      "Test = 32.84820556640625 30.316267013549805\n",
      "[33,   121] loss: 226.892\n",
      "Test = 31.94550323486328 28.880630493164062\n",
      "[33,   141] loss: 221.386\n",
      "Test = 34.90069580078125 31.163686752319336\n",
      "[33,   161] loss: 269.306\n",
      "Test = 31.70401382446289 29.390148162841797\n",
      "[33,   181] loss: 255.705\n",
      "Test = 32.95214080810547 30.953290939331055\n",
      "[33,   201] loss: 259.148\n",
      "Test = 32.166568756103516 30.412464141845703\n",
      "[33,   221] loss: 359.232\n",
      "Test = 33.63120651245117 31.005537033081055\n",
      "[34,     1] loss: 277.804\n",
      "Test = 31.186771392822266 28.117780685424805\n",
      "[34,    21] loss: 338.149\n",
      "Test = 33.63633728027344 30.019784927368164\n",
      "[34,    41] loss: 227.231\n",
      "Test = 30.649211883544922 28.580821990966797\n",
      "[34,    61] loss: 305.018\n",
      "Test = 31.253023147583008 29.384078979492188\n",
      "[34,    81] loss: 238.850\n",
      "Test = 31.49433708190918 29.24294090270996\n",
      "[34,   101] loss: 228.586\n",
      "Test = 32.85019302368164 30.437345504760742\n",
      "[34,   121] loss: 226.047\n",
      "Test = 31.90289878845215 29.118438720703125\n",
      "[34,   141] loss: 219.590\n",
      "Test = 34.78524398803711 31.589889526367188\n",
      "[34,   161] loss: 268.515\n",
      "Test = 31.45620346069336 29.234434127807617\n",
      "[34,   181] loss: 254.548\n",
      "Test = 32.665618896484375 30.755983352661133\n",
      "[34,   201] loss: 260.236\n",
      "Test = 32.04926681518555 30.3879451751709\n",
      "[34,   221] loss: 356.450\n",
      "Test = 33.64433670043945 31.5060977935791\n",
      "[35,     1] loss: 277.620\n",
      "Test = 31.119674682617188 28.78650665283203\n",
      "[35,    21] loss: 340.200\n",
      "Test = 33.594993591308594 30.424835205078125\n",
      "[35,    41] loss: 227.374\n",
      "Test = 30.676013946533203 28.760725021362305\n",
      "[35,    61] loss: 306.498\n",
      "Test = 31.337383270263672 29.64432144165039\n",
      "[35,    81] loss: 237.756\n",
      "Test = 31.425947189331055 29.529489517211914\n",
      "[35,   101] loss: 229.589\n",
      "Test = 32.603485107421875 30.518402099609375\n",
      "[35,   121] loss: 225.728\n",
      "Test = 31.786998748779297 29.175500869750977\n",
      "[35,   141] loss: 219.045\n",
      "Test = 34.608909606933594 31.897790908813477\n",
      "[35,   161] loss: 269.699\n",
      "Test = 31.37689971923828 29.825368881225586\n",
      "[35,   181] loss: 254.906\n",
      "Test = 32.41727066040039 31.102373123168945\n",
      "[35,   201] loss: 258.276\n",
      "Test = 31.9647159576416 30.71120834350586\n",
      "[35,   221] loss: 357.189\n",
      "Test = 33.55934143066406 31.67062759399414\n",
      "[36,     1] loss: 277.052\n",
      "Test = 31.07794761657715 28.919004440307617\n",
      "[36,    21] loss: 337.880\n",
      "Test = 33.57801818847656 30.724884033203125\n",
      "[36,    41] loss: 227.970\n",
      "Test = 30.62925148010254 28.800722122192383\n",
      "[36,    61] loss: 307.988\n",
      "Test = 31.061342239379883 29.468006134033203\n",
      "[36,    81] loss: 236.829\n",
      "Test = 31.178997039794922 29.722057342529297\n",
      "[36,   101] loss: 230.486\n",
      "Test = 32.36040496826172 31.003618240356445\n",
      "[36,   121] loss: 225.064\n",
      "Test = 31.60663604736328 29.465587615966797\n",
      "[36,   141] loss: 218.617\n",
      "Test = 34.45135498046875 32.014556884765625\n",
      "[36,   161] loss: 269.702\n",
      "Test = 31.11446189880371 29.871732711791992\n",
      "[36,   181] loss: 255.223\n",
      "Test = 32.32931900024414 31.38733673095703\n",
      "[36,   201] loss: 258.583\n",
      "Test = 31.99421501159668 30.972227096557617\n",
      "[36,   221] loss: 356.426\n",
      "Test = 33.38738250732422 31.716392517089844\n",
      "[37,     1] loss: 277.080\n",
      "Test = 30.85735321044922 28.75895118713379\n",
      "[37,    21] loss: 337.748\n",
      "Test = 33.31452941894531 30.73688316345215\n",
      "[37,    41] loss: 227.677\n",
      "Test = 30.450849533081055 28.983469009399414\n",
      "[37,    61] loss: 306.044\n",
      "Test = 30.7996883392334 29.61836051940918\n",
      "[37,    81] loss: 236.945\n",
      "Test = 30.98103904724121 29.789512634277344\n",
      "[37,   101] loss: 229.191\n",
      "Test = 31.940717697143555 30.87332534790039\n",
      "[37,   121] loss: 224.105\n",
      "Test = 31.36688804626465 29.52744483947754\n",
      "[37,   141] loss: 219.020\n",
      "Test = 34.20425796508789 32.11040496826172\n",
      "[37,   161] loss: 268.974\n",
      "Test = 30.69963264465332 30.019006729125977\n",
      "[37,   181] loss: 255.359\n",
      "Test = 32.06169891357422 31.333635330200195\n",
      "[37,   201] loss: 259.095\n",
      "Test = 31.877939224243164 31.215059280395508\n",
      "[37,   221] loss: 354.151\n",
      "Test = 33.15413284301758 31.878482818603516\n",
      "[38,     1] loss: 278.387\n",
      "Test = 30.67487144470215 28.950878143310547\n",
      "[38,    21] loss: 338.629\n",
      "Test = 33.11579513549805 30.40101432800293\n",
      "[38,    41] loss: 227.967\n",
      "Test = 30.47410774230957 29.153411865234375\n",
      "[38,    61] loss: 305.365\n",
      "Test = 30.712291717529297 29.680288314819336\n",
      "[38,    81] loss: 236.374\n",
      "Test = 30.801210403442383 29.940107345581055\n",
      "[38,   101] loss: 230.583\n",
      "Test = 31.744264602661133 31.009117126464844\n",
      "[38,   121] loss: 222.497\n",
      "Test = 31.193761825561523 29.604814529418945\n",
      "[38,   141] loss: 217.677\n",
      "Test = 33.84461212158203 32.40978240966797\n",
      "[38,   161] loss: 269.480\n",
      "Test = 30.404848098754883 30.137493133544922\n",
      "[38,   181] loss: 255.976\n",
      "Test = 31.789344787597656 31.51187515258789\n",
      "[38,   201] loss: 258.661\n",
      "Test = 31.864389419555664 31.398923873901367\n",
      "[38,   221] loss: 353.608\n",
      "Test = 33.097679138183594 32.076786041259766\n",
      "[39,     1] loss: 277.716\n",
      "Test = 30.623592376708984 29.248945236206055\n",
      "[39,    21] loss: 338.173\n",
      "Test = 32.99504852294922 30.367183685302734\n",
      "[39,    41] loss: 228.185\n",
      "Test = 30.494850158691406 29.191133499145508\n",
      "[39,    61] loss: 304.556\n",
      "Test = 30.535062789916992 29.89999771118164\n",
      "[39,    81] loss: 236.761\n",
      "Test = 30.690690994262695 30.326940536499023\n",
      "[39,   101] loss: 229.139\n",
      "Test = 31.68798828125 31.276634216308594\n",
      "[39,   121] loss: 222.007\n",
      "Test = 31.1402587890625 29.928361892700195\n",
      "[39,   141] loss: 216.497\n",
      "Test = 33.79965591430664 32.8229866027832\n",
      "[39,   161] loss: 269.680\n",
      "Test = 30.34795379638672 30.589252471923828\n",
      "[39,   181] loss: 256.350\n",
      "Test = 31.615325927734375 31.937849044799805\n",
      "[39,   201] loss: 259.448\n",
      "Test = 31.967634201049805 31.921815872192383\n",
      "[39,   221] loss: 354.235\n",
      "Test = 33.2878532409668 32.56704330444336\n",
      "[40,     1] loss: 278.134\n",
      "Test = 30.803274154663086 29.5828914642334\n",
      "[40,    21] loss: 338.807\n",
      "Test = 32.854278564453125 31.25508689880371\n",
      "[40,    41] loss: 228.080\n",
      "Test = 30.47917938232422 29.341299057006836\n",
      "[40,    61] loss: 304.965\n",
      "Test = 30.40794563293457 30.082387924194336\n",
      "[40,    81] loss: 235.769\n",
      "Test = 30.613943099975586 30.739194869995117\n",
      "[40,   101] loss: 230.251\n",
      "Test = 31.609638214111328 31.762178421020508\n",
      "[40,   121] loss: 221.873\n",
      "Test = 31.087635040283203 30.280357360839844\n",
      "[40,   141] loss: 217.291\n",
      "Test = 33.741451263427734 33.59531784057617\n",
      "[40,   161] loss: 270.372\n",
      "Test = 30.208282470703125 31.102922439575195\n",
      "[40,   181] loss: 257.326\n",
      "Test = 31.285533905029297 32.31245422363281\n",
      "[40,   201] loss: 257.458\n",
      "Test = 31.75235366821289 32.090484619140625\n",
      "[40,   221] loss: 353.500\n",
      "Test = 33.11081314086914 33.125797271728516\n",
      "[41,     1] loss: 278.695\n",
      "Test = 30.7155818939209 30.70005989074707\n",
      "[41,    21] loss: 339.354\n",
      "Test = 32.91813659667969 31.61012077331543\n",
      "[41,    41] loss: 228.047\n",
      "Test = 30.556482315063477 29.744525909423828\n",
      "[41,    61] loss: 302.509\n",
      "Test = 30.198806762695312 30.32509422302246\n",
      "[41,    81] loss: 234.642\n",
      "Test = 30.35472869873047 31.217130661010742\n",
      "[41,   101] loss: 231.465\n",
      "Test = 31.42546844482422 32.16552734375\n",
      "[41,   121] loss: 221.481\n",
      "Test = 30.975427627563477 30.7960205078125\n",
      "[41,   141] loss: 215.781\n",
      "Test = 33.759517669677734 33.39821243286133\n",
      "[41,   161] loss: 268.348\n",
      "Test = 30.27032470703125 31.171051025390625\n",
      "[41,   181] loss: 258.175\n",
      "Test = 31.137569427490234 32.27094268798828\n",
      "[41,   201] loss: 255.836\n",
      "Test = 31.479389190673828 32.028892517089844\n",
      "[41,   221] loss: 352.740\n",
      "Test = 32.89073944091797 33.34911346435547\n",
      "[42,     1] loss: 277.846\n",
      "Test = 30.759723663330078 31.228891372680664\n",
      "[42,    21] loss: 341.105\n",
      "Test = 32.894710540771484 31.173568725585938\n",
      "[42,    41] loss: 228.068\n",
      "Test = 30.694229125976562 29.968297958374023\n",
      "[42,    61] loss: 303.279\n",
      "Test = 30.237506866455078 30.426746368408203\n",
      "[42,    81] loss: 234.034\n",
      "Test = 30.57308578491211 31.49848747253418\n",
      "[42,   101] loss: 231.811\n",
      "Test = 31.481258392333984 32.199893951416016\n",
      "[42,   121] loss: 221.342\n",
      "Test = 30.863882064819336 30.811614990234375\n",
      "[42,   141] loss: 215.951\n",
      "Test = 33.575984954833984 33.66045379638672\n",
      "[42,   161] loss: 267.554\n",
      "Test = 30.09256362915039 31.509382247924805\n",
      "[42,   181] loss: 258.792\n",
      "Test = 31.017257690429688 32.554744720458984\n",
      "[42,   201] loss: 257.058\n",
      "Test = 31.518400192260742 32.261070251464844\n",
      "[42,   221] loss: 353.948\n",
      "Test = 32.914085388183594 33.54084777832031\n",
      "[43,     1] loss: 278.725\n",
      "Test = 30.835880279541016 30.85356903076172\n",
      "[43,    21] loss: 340.558\n",
      "Test = 32.52827072143555 31.15386962890625\n",
      "[43,    41] loss: 228.376\n",
      "Test = 30.69302749633789 29.82056427001953\n",
      "[43,    61] loss: 302.620\n",
      "Test = 30.265348434448242 30.485048294067383\n",
      "[43,    81] loss: 232.763\n",
      "Test = 30.426767349243164 31.544170379638672\n",
      "[43,   101] loss: 232.581\n",
      "Test = 31.265138626098633 32.41749572753906\n",
      "[43,   121] loss: 219.879\n",
      "Test = 30.71969223022461 31.0325927734375\n",
      "[43,   141] loss: 215.966\n",
      "Test = 33.54893493652344 34.01488494873047\n",
      "[43,   161] loss: 267.421\n",
      "Test = 29.918455123901367 32.099647521972656\n",
      "[43,   181] loss: 261.284\n",
      "Test = 30.977031707763672 32.65214920043945\n",
      "[43,   201] loss: 256.606\n",
      "Test = 31.50992774963379 32.4506950378418\n",
      "[43,   221] loss: 354.137\n",
      "Test = 32.73503494262695 33.64590072631836\n",
      "[44,     1] loss: 279.404\n",
      "Test = 30.792160034179688 31.088010787963867\n",
      "[44,    21] loss: 339.318\n",
      "Test = 32.62527847290039 31.614673614501953\n",
      "[44,    41] loss: 228.986\n",
      "Test = 30.940446853637695 30.29189682006836\n",
      "[44,    61] loss: 299.743\n",
      "Test = 30.570587158203125 30.650012969970703\n",
      "[44,    81] loss: 232.262\n",
      "Test = 30.557222366333008 31.9520206451416\n",
      "[44,   101] loss: 233.360\n",
      "Test = 31.40083885192871 32.376564025878906\n",
      "[44,   121] loss: 220.533\n",
      "Test = 30.8037052154541 30.967439651489258\n",
      "[44,   141] loss: 215.689\n",
      "Test = 33.5801887512207 33.684207916259766\n",
      "[44,   161] loss: 266.288\n",
      "Test = 30.15252113342285 31.76030921936035\n",
      "[44,   181] loss: 261.225\n",
      "Test = 30.993988037109375 31.940326690673828\n",
      "[44,   201] loss: 254.821\n",
      "Test = 31.282917022705078 31.4595947265625\n",
      "[44,   221] loss: 354.406\n",
      "Test = 32.52663803100586 33.40774154663086\n",
      "[45,     1] loss: 279.214\n",
      "Test = 30.898595809936523 31.273958206176758\n",
      "[45,    21] loss: 341.731\n",
      "Test = 32.74721908569336 31.9747371673584\n",
      "[45,    41] loss: 230.151\n",
      "Test = 31.209184646606445 30.834774017333984\n",
      "[45,    61] loss: 301.908\n",
      "Test = 30.836040496826172 30.54216957092285\n",
      "[45,    81] loss: 231.536\n",
      "Test = 30.89105987548828 32.00571823120117\n",
      "[45,   101] loss: 234.075\n",
      "Test = 31.635828018188477 32.743080139160156\n",
      "[45,   121] loss: 221.619\n",
      "Test = 31.046812057495117 31.219308853149414\n",
      "[45,   141] loss: 214.997\n",
      "Test = 33.80380630493164 33.93045425415039\n",
      "[45,   161] loss: 265.542\n",
      "Test = 30.365934371948242 31.742443084716797\n",
      "[45,   181] loss: 261.759\n",
      "Test = 31.044700622558594 31.918201446533203\n",
      "[45,   201] loss: 255.956\n",
      "Test = 31.605955123901367 31.53833770751953\n",
      "[45,   221] loss: 353.376\n",
      "Test = 32.67049026489258 33.44818115234375\n",
      "[46,     1] loss: 279.162\n",
      "Test = 31.19862937927246 31.492956161499023\n",
      "[46,    21] loss: 342.536\n",
      "Test = 32.95197677612305 31.64227294921875\n",
      "[46,    41] loss: 229.928\n",
      "Test = 31.341278076171875 30.726545333862305\n",
      "[46,    61] loss: 299.987\n",
      "Test = 30.922082901000977 30.77389144897461\n",
      "[46,    81] loss: 228.972\n",
      "Test = 30.984966278076172 31.515411376953125\n",
      "[46,   101] loss: 234.015\n",
      "Test = 31.513572692871094 32.8368034362793\n",
      "[46,   121] loss: 221.156\n",
      "Test = 31.04894256591797 31.2619686126709\n",
      "[46,   141] loss: 214.704\n",
      "Test = 34.1348876953125 33.93745422363281\n",
      "[46,   161] loss: 266.950\n",
      "Test = 30.536678314208984 31.67547607421875\n",
      "[46,   181] loss: 262.081\n",
      "Test = 31.277263641357422 31.89562225341797\n",
      "[46,   201] loss: 255.548\n",
      "Test = 31.685035705566406 31.181215286254883\n",
      "[46,   221] loss: 351.940\n",
      "Test = 32.66449737548828 33.33271408081055\n",
      "[47,     1] loss: 279.608\n",
      "Test = 31.174448013305664 31.25190544128418\n",
      "[47,    21] loss: 339.113\n",
      "Test = 33.07639694213867 31.987071990966797\n",
      "[47,    41] loss: 230.327\n",
      "Test = 31.52725601196289 30.353864669799805\n",
      "[47,    61] loss: 298.917\n",
      "Test = 31.25565528869629 30.375062942504883\n",
      "[47,    81] loss: 229.433\n",
      "Test = 31.03471565246582 31.66594123840332\n",
      "[47,   101] loss: 235.393\n",
      "Test = 31.559471130371094 32.44042205810547\n",
      "[47,   121] loss: 221.415\n",
      "Test = 31.141271591186523 30.937292098999023\n",
      "[47,   141] loss: 215.449\n",
      "Test = 33.924190521240234 33.674781799316406\n",
      "[47,   161] loss: 265.123\n",
      "Test = 30.607873916625977 31.75935173034668\n",
      "[47,   181] loss: 263.525\n",
      "Test = 31.252548217773438 32.14299392700195\n",
      "[47,   201] loss: 256.572\n",
      "Test = 31.713769912719727 31.40019416809082\n",
      "[47,   221] loss: 351.313\n",
      "Test = 32.44143295288086 33.349117279052734\n",
      "[48,     1] loss: 281.470\n",
      "Test = 30.94160270690918 31.1992130279541\n",
      "[48,    21] loss: 338.245\n",
      "Test = 32.8210563659668 31.99112319946289\n",
      "[48,    41] loss: 229.895\n",
      "Test = 31.505104064941406 30.1075496673584\n",
      "[48,    61] loss: 297.360\n",
      "Test = 31.093137741088867 30.790796279907227\n",
      "[48,    81] loss: 227.382\n",
      "Test = 31.18046760559082 31.55019187927246\n",
      "[48,   101] loss: 236.034\n",
      "Test = 31.651140213012695 32.34990692138672\n",
      "[48,   121] loss: 221.193\n",
      "Test = 31.22340965270996 31.239988327026367\n",
      "[48,   141] loss: 216.038\n",
      "Test = 34.15345001220703 34.10950469970703\n",
      "[48,   161] loss: 265.583\n",
      "Test = 30.818593978881836 31.6368408203125\n",
      "[48,   181] loss: 261.159\n",
      "Test = 31.482290267944336 31.844675064086914\n",
      "[48,   201] loss: 256.096\n",
      "Test = 31.87327766418457 31.596641540527344\n",
      "[48,   221] loss: 353.038\n",
      "Test = 33.0566291809082 33.31952667236328\n",
      "[49,     1] loss: 280.256\n",
      "Test = 31.430723190307617 31.37919807434082\n",
      "[49,    21] loss: 339.220\n",
      "Test = 32.974815368652344 32.52792739868164\n",
      "[49,    41] loss: 230.702\n",
      "Test = 31.58260726928711 30.84136390686035\n",
      "[49,    61] loss: 296.353\n",
      "Test = 31.2412166595459 30.919458389282227\n",
      "[49,    81] loss: 226.660\n",
      "Test = 31.41272735595703 31.73530387878418\n",
      "[49,   101] loss: 236.101\n",
      "Test = 31.67428970336914 32.43479537963867\n",
      "[49,   121] loss: 220.962\n",
      "Test = 31.23822593688965 31.410503387451172\n",
      "[49,   141] loss: 216.833\n",
      "Test = 34.198246002197266 34.669010162353516\n",
      "[49,   161] loss: 266.106\n",
      "Test = 30.982521057128906 31.919801712036133\n",
      "[49,   181] loss: 260.145\n",
      "Test = 31.55195426940918 32.180538177490234\n",
      "[49,   201] loss: 255.155\n",
      "Test = 31.805553436279297 31.74262046813965\n",
      "[49,   221] loss: 351.886\n",
      "Test = 32.955989837646484 33.69719314575195\n",
      "[50,     1] loss: 280.433\n",
      "Test = 31.33697509765625 31.32229232788086\n",
      "[50,    21] loss: 337.626\n",
      "Test = 33.26164245605469 32.56601333618164\n",
      "[50,    41] loss: 229.906\n",
      "Test = 31.94569969177246 30.673234939575195\n",
      "[50,    61] loss: 296.210\n",
      "Test = 31.78550910949707 31.094026565551758\n",
      "[50,    81] loss: 225.957\n",
      "Test = 31.599933624267578 31.69338035583496\n",
      "[50,   101] loss: 237.065\n",
      "Test = 32.0882682800293 32.323429107666016\n",
      "[50,   121] loss: 221.949\n",
      "Test = 31.52303123474121 31.24183464050293\n",
      "[50,   141] loss: 217.154\n",
      "Test = 34.444950103759766 34.40834426879883\n",
      "[50,   161] loss: 264.717\n",
      "Test = 31.16839599609375 32.063568115234375\n",
      "[50,   181] loss: 260.918\n",
      "Test = 31.776599884033203 31.93967056274414\n",
      "[50,   201] loss: 254.651\n",
      "Test = 32.21896743774414 31.951332092285156\n",
      "[50,   221] loss: 350.205\n",
      "Test = 33.13504409790039 33.786685943603516\n",
      "[51,     1] loss: 280.464\n",
      "Test = 31.508930206298828 31.615636825561523\n",
      "[51,    21] loss: 336.424\n",
      "Test = 33.321903228759766 32.561344146728516\n",
      "[51,    41] loss: 228.646\n",
      "Test = 32.06060791015625 30.74070930480957\n",
      "[51,    61] loss: 294.744\n",
      "Test = 31.680255889892578 31.3599853515625\n",
      "[51,    81] loss: 227.006\n",
      "Test = 31.737276077270508 32.009422302246094\n",
      "[51,   101] loss: 236.211\n",
      "Test = 32.0484619140625 32.689353942871094\n",
      "[51,   121] loss: 220.706\n",
      "Test = 31.440282821655273 31.427045822143555\n",
      "[51,   141] loss: 213.957\n",
      "Test = 34.472469329833984 34.423641204833984\n",
      "[51,   161] loss: 264.714\n",
      "Test = 31.298198699951172 32.07182312011719\n",
      "[51,   181] loss: 261.160\n",
      "Test = 31.869709014892578 31.976680755615234\n",
      "[51,   201] loss: 255.845\n",
      "Test = 32.31473159790039 32.01015853881836\n",
      "[51,   221] loss: 350.058\n",
      "Test = 33.142799377441406 33.405513763427734\n",
      "[52,     1] loss: 280.186\n",
      "Test = 31.569002151489258 31.113046646118164\n",
      "[52,    21] loss: 335.805\n",
      "Test = 33.40623474121094 32.25553512573242\n",
      "[52,    41] loss: 229.661\n",
      "Test = 32.25168228149414 30.250450134277344\n",
      "[52,    61] loss: 297.671\n",
      "Test = 31.89235496520996 30.9644832611084\n",
      "[52,    81] loss: 225.749\n",
      "Test = 31.84052848815918 31.717451095581055\n",
      "[52,   101] loss: 236.535\n",
      "Test = 32.201820373535156 32.721435546875\n",
      "[52,   121] loss: 220.653\n",
      "Test = 31.58942222595215 31.40355682373047\n",
      "[52,   141] loss: 214.841\n",
      "Test = 34.630619049072266 34.387935638427734\n",
      "[52,   161] loss: 263.277\n",
      "Test = 31.28486442565918 32.07643127441406\n",
      "[52,   181] loss: 262.068\n",
      "Test = 31.778335571289062 32.08747100830078\n",
      "[52,   201] loss: 254.912\n",
      "Test = 32.206966400146484 32.05808639526367\n",
      "[52,   221] loss: 351.748\n",
      "Test = 33.02358627319336 33.541709899902344\n",
      "[53,     1] loss: 281.026\n",
      "Test = 31.470272064208984 31.3292293548584\n",
      "[53,    21] loss: 335.748\n",
      "Test = 33.397369384765625 32.52033996582031\n",
      "[53,    41] loss: 229.498\n",
      "Test = 32.225242614746094 30.454063415527344\n",
      "[53,    61] loss: 296.809\n",
      "Test = 31.913589477539062 31.141956329345703\n",
      "[53,    81] loss: 225.412\n",
      "Test = 31.788768768310547 31.74480438232422\n",
      "[53,   101] loss: 237.046\n",
      "Test = 32.441898345947266 32.88047790527344\n",
      "[53,   121] loss: 220.940\n",
      "Test = 31.637691497802734 31.26155662536621\n",
      "[53,   141] loss: 214.637\n",
      "Test = 34.57431411743164 34.34836959838867\n",
      "[53,   161] loss: 263.723\n",
      "Test = 31.571130752563477 31.95975685119629\n",
      "[53,   181] loss: 261.346\n",
      "Test = 32.23942947387695 31.97350311279297\n",
      "[53,   201] loss: 254.671\n",
      "Test = 32.44069290161133 31.730052947998047\n",
      "[53,   221] loss: 350.467\n",
      "Test = 33.09066390991211 33.13800811767578\n",
      "[54,     1] loss: 280.595\n",
      "Test = 31.498151779174805 30.617107391357422\n",
      "[54,    21] loss: 332.446\n",
      "Test = 33.420074462890625 32.46656799316406\n",
      "[54,    41] loss: 230.172\n",
      "Test = 32.526519775390625 30.269691467285156\n",
      "[54,    61] loss: 295.925\n",
      "Test = 32.25274658203125 30.9361572265625\n",
      "[54,    81] loss: 226.545\n",
      "Test = 32.00694274902344 31.343950271606445\n",
      "[54,   101] loss: 236.930\n",
      "Test = 32.55686950683594 32.542598724365234\n",
      "[54,   121] loss: 219.828\n",
      "Test = 31.769807815551758 31.193838119506836\n",
      "[54,   141] loss: 213.703\n",
      "Test = 34.84795379638672 34.27556228637695\n",
      "[54,   161] loss: 264.395\n",
      "Test = 31.61585235595703 31.746049880981445\n",
      "[54,   181] loss: 262.248\n",
      "Test = 32.18174362182617 32.228240966796875\n",
      "[54,   201] loss: 254.894\n",
      "Test = 32.50973129272461 32.1462287902832\n",
      "[54,   221] loss: 350.876\n",
      "Test = 33.51068115234375 32.86945724487305\n",
      "[55,     1] loss: 280.448\n",
      "Test = 31.815471649169922 29.816753387451172\n",
      "[55,    21] loss: 333.300\n",
      "Test = 33.21970748901367 31.75653648376465\n",
      "[55,    41] loss: 230.990\n",
      "Test = 32.35493850708008 30.1009521484375\n",
      "[55,    61] loss: 295.498\n",
      "Test = 32.04124450683594 30.595314025878906\n",
      "[55,    81] loss: 225.623\n",
      "Test = 31.820356369018555 31.209745407104492\n",
      "[55,   101] loss: 236.845\n",
      "Test = 32.56686782836914 31.992755889892578\n",
      "[55,   121] loss: 219.472\n",
      "Test = 31.925785064697266 30.940378189086914\n",
      "[55,   141] loss: 214.658\n",
      "Test = 34.82936096191406 33.927268981933594\n",
      "[55,   161] loss: 264.114\n",
      "Test = 31.66288948059082 31.38579559326172\n",
      "[55,   181] loss: 261.932\n",
      "Test = 32.24271011352539 31.859304428100586\n",
      "[55,   201] loss: 254.120\n",
      "Test = 32.76295471191406 31.876373291015625\n",
      "[55,   221] loss: 351.505\n",
      "Test = 33.44817352294922 32.92755889892578\n",
      "[56,     1] loss: 283.941\n",
      "Test = 31.927583694458008 29.876155853271484\n",
      "[56,    21] loss: 334.543\n",
      "Test = 33.534488677978516 31.403270721435547\n",
      "[56,    41] loss: 232.023\n",
      "Test = 32.69905471801758 29.70819664001465\n",
      "[56,    61] loss: 295.189\n",
      "Test = 32.210243225097656 30.48100471496582\n",
      "[56,    81] loss: 226.129\n",
      "Test = 31.80228042602539 31.31721305847168\n",
      "[56,   101] loss: 237.413\n",
      "Test = 32.52240753173828 32.145294189453125\n",
      "[56,   121] loss: 218.899\n",
      "Test = 31.82200813293457 31.013389587402344\n",
      "[56,   141] loss: 215.036\n",
      "Test = 34.891849517822266 33.61146926879883\n",
      "[56,   161] loss: 264.863\n",
      "Test = 31.87321662902832 31.06031608581543\n",
      "[56,   181] loss: 260.967\n",
      "Test = 32.28622055053711 31.048282623291016\n",
      "[56,   201] loss: 251.947\n",
      "Test = 32.7864990234375 31.38548469543457\n",
      "[56,   221] loss: 353.174\n",
      "Test = 33.27320098876953 32.67814636230469\n",
      "[57,     1] loss: 282.402\n",
      "Test = 31.904006958007812 30.514366149902344\n",
      "[57,    21] loss: 332.821\n",
      "Test = 33.70429992675781 32.082847595214844\n",
      "[57,    41] loss: 231.341\n",
      "Test = 32.84987258911133 30.399118423461914\n",
      "[57,    61] loss: 293.313\n",
      "Test = 32.42540740966797 30.785743713378906\n",
      "[57,    81] loss: 224.736\n",
      "Test = 32.14948654174805 31.414100646972656\n",
      "[57,   101] loss: 238.965\n",
      "Test = 32.856468200683594 32.19537353515625\n",
      "[57,   121] loss: 218.641\n",
      "Test = 32.0165901184082 30.747087478637695\n",
      "[57,   141] loss: 212.673\n",
      "Test = 35.070213317871094 33.542659759521484\n",
      "[57,   161] loss: 261.880\n",
      "Test = 32.176815032958984 30.537073135375977\n",
      "[57,   181] loss: 261.956\n",
      "Test = 32.215728759765625 31.338708877563477\n",
      "[57,   201] loss: 253.319\n",
      "Test = 33.055938720703125 31.862361907958984\n",
      "[57,   221] loss: 350.834\n",
      "Test = 33.449729919433594 32.522239685058594\n",
      "[58,     1] loss: 282.627\n",
      "Test = 32.20946502685547 30.025924682617188\n",
      "[58,    21] loss: 331.947\n",
      "Test = 33.7518310546875 31.593236923217773\n",
      "[58,    41] loss: 233.098\n",
      "Test = 33.004459381103516 29.951688766479492\n",
      "[58,    61] loss: 295.137\n",
      "Test = 32.465938568115234 30.273521423339844\n",
      "[58,    81] loss: 225.140\n",
      "Test = 32.132850646972656 31.20693588256836\n",
      "[58,   101] loss: 238.896\n",
      "Test = 33.0676383972168 32.10538864135742\n",
      "[58,   121] loss: 217.765\n",
      "Test = 32.332515716552734 30.922039031982422\n",
      "[58,   141] loss: 212.200\n",
      "Test = 35.1715202331543 33.182044982910156\n",
      "[58,   161] loss: 260.512\n",
      "Test = 32.15644836425781 30.289350509643555\n",
      "[58,   181] loss: 259.216\n",
      "Test = 32.10432052612305 30.623733520507812\n",
      "[58,   201] loss: 251.303\n",
      "Test = 32.97726821899414 31.197860717773438\n",
      "[58,   221] loss: 350.889\n",
      "Test = 33.339744567871094 32.027217864990234\n",
      "[59,     1] loss: 282.774\n",
      "Test = 32.040069580078125 29.58074378967285\n",
      "[59,    21] loss: 331.109\n",
      "Test = 34.00058364868164 31.19097900390625\n",
      "[59,    41] loss: 233.592\n",
      "Test = 33.015716552734375 29.378429412841797\n",
      "[59,    61] loss: 296.056\n",
      "Test = 32.486454010009766 29.68254280090332\n",
      "[59,    81] loss: 224.271\n",
      "Test = 32.35624313354492 30.594741821289062\n",
      "[59,   101] loss: 239.929\n",
      "Test = 33.25125503540039 31.752567291259766\n",
      "[59,   121] loss: 218.097\n",
      "Test = 32.477325439453125 30.697059631347656\n",
      "[59,   141] loss: 213.378\n",
      "Test = 35.413936614990234 32.981834411621094\n",
      "[59,   161] loss: 261.908\n",
      "Test = 32.5096549987793 30.309080123901367\n",
      "[59,   181] loss: 258.545\n",
      "Test = 32.67136764526367 30.542234420776367\n",
      "[59,   201] loss: 252.677\n",
      "Test = 33.50054931640625 30.928234100341797\n",
      "[59,   221] loss: 349.374\n",
      "Test = 33.78160858154297 32.03190612792969\n",
      "[60,     1] loss: 283.861\n",
      "Test = 32.38936996459961 29.042591094970703\n",
      "[60,    21] loss: 331.591\n",
      "Test = 34.57501983642578 30.75901985168457\n",
      "[60,    41] loss: 233.018\n",
      "Test = 33.57097625732422 29.417404174804688\n",
      "[60,    61] loss: 296.342\n",
      "Test = 33.180912017822266 29.66956901550293\n",
      "[60,    81] loss: 222.843\n",
      "Test = 32.830509185791016 30.201629638671875\n",
      "[60,   101] loss: 239.595\n",
      "Test = 33.47784423828125 31.566181182861328\n",
      "[60,   121] loss: 216.965\n",
      "Test = 32.48836898803711 30.401552200317383\n",
      "[60,   141] loss: 212.520\n",
      "Test = 35.417823791503906 32.502601623535156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8de52a654ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#loss = ( outputs - labels )**2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-60f6f33e6646>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Defining the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "#from torch.nn import L1Loss\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=10e-6, momentum=0.95)\n",
    "#criterion = L1Loss()\n",
    "\n",
    "loss_plot = [ [], [] ]\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs,labels) in enumerate( zip( batch_data, batch_ans_data ) ):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net( inputs.float() )\n",
    "        #loss = ( outputs - labels )**2.0\n",
    "        loss = torch.mean( ( outputs[:,0] - labels )**2.0 )\n",
    "        #loss = criterion( outputs[:,0], labels )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        \n",
    "        loss_plot[0].append( i + epoch * len(batch_data) )\n",
    "        loss_plot[1].append( loss.item() )\n",
    "        \n",
    "        #print( outputs, labels )\n",
    "        if i % 20 == 0 : #i % 1000 == 1000 - 1:    # print every 2000 mini-batches\n",
    "            print( '[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item() ) )\n",
    "            print( 'Test =', net( train_data[0].float() ).item(), net( train_data[1].float() ).item() )\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0f6316b410>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot( loss_plot[0], loss_plot[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.1267, 21.0215, 23.4486, 29.0702, 25.0288, 33.0197, 29.1144, 30.7057,\n",
       "        32.5212, 29.0400, 24.6836, 17.8344, 34.6314, 40.5332, 17.9979, 35.8910,\n",
       "        37.0301, 25.7292, 33.1206, 36.8760, 25.6732, 32.1442, 19.4441, 29.3572,\n",
       "        26.4550, 47.0285, 25.2724, 25.5403, 36.4661, 31.4612, 28.5465, 29.4981,\n",
       "        30.6531, 23.1798, 32.5789, 30.6820, 39.0094, 11.9133, 27.5899, 35.9370,\n",
       "        35.1398, 16.7658, 31.0877, 21.7008, 42.0343, 19.4606, 29.6308, 26.1077,\n",
       "        21.4473, 34.3523, 27.8042, 22.9143, 35.2841, 22.2327, 35.8741, 38.1098,\n",
       "        19.5683, 23.5931, 27.9297, 35.5297, 26.5219, 32.9863, 30.2562, 40.1617,\n",
       "        33.1889, 22.8866, 24.8758, 35.8870, 23.7229, 28.4670, 33.7398, 21.7962,\n",
       "        24.3685, 39.6090, 30.6358, 29.3107, 10.9133, 25.0062, 32.9603, 27.5917,\n",
       "        24.3459, 35.6334, 31.5141, 38.5714, 33.6356, 24.3191, 40.4372, 30.1605,\n",
       "        17.9530, 32.0870, 31.6394, 21.4060, 27.9687, 29.0737, 37.2516, 37.2285,\n",
       "        32.6167, 15.4580, 31.5784, 22.4759], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.0182, 15.5767, 41.7014, 53.0310, 25.5131, 51.0569, 48.7170, 79.2410,\n",
       "        22.5334, 41.3524, 17.6372, 12.5715, 73.8777, 35.9623, 38.9937, 38.0874,\n",
       "        68.6073, 18.2507, 18.2703, 25.6499, 52.4302, 22.2456, 14.3237, 42.8813,\n",
       "        15.5952, 23.8115, 49.0974, 49.0466, 18.1766, 12.9878, 38.9713, 40.8019,\n",
       "        39.2880, 13.6157, 41.3237, 17.3279, 43.7137, 12.7371, 24.1051, 64.7263,\n",
       "        26.3618, 13.1803, 35.0052, 12.0717, 82.9658, 14.8160, 16.7922, 19.2915,\n",
       "        22.3839, 78.1140, 21.1267, 55.8741, 49.8474, 52.3157, 20.8414, 40.6985,\n",
       "        18.1781, 22.3818, 20.1986, 57.3737, 47.3464, 46.1805, 18.3068, 14.2412,\n",
       "        25.1653, 64.3138, 24.0580, 69.3617, 42.2439, 19.0336, 61.2217, 14.8301,\n",
       "        13.3885, 63.3660, 17.5238, 12.3361, 22.6265, 29.4226, 70.3064, 15.9906,\n",
       "        19.0691, 69.2628, 15.9868, 25.0061, 70.2240, 53.2316, 51.2600, 11.0099,\n",
       "         6.7311, 20.4058, 10.1279, 16.0742, 45.8842, 23.9897, 40.0656, 17.9863,\n",
       "        12.4193, 13.3854, 13.2865, 12.9309], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(347.4461, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean( torch.abs( outputs[:,0] - labels )**2.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.447021484375, 11.91796875]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ans_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7f0f88022550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "trues = [ x.item() for x in train_ans_data ]\n",
    "preds = [ net(x.float()).item() for x in train_data ]\n",
    "\n",
    "sns.jointplot( trues, preds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value =  9.078155101078826e-146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.019545062116703687, intercept=29.2059652089479, rvalue=0.16613783728243445, pvalue=9.078155101078826e-146, stderr=0.0007548964961972685)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "res = scipy.stats.linregress(trues, preds)\n",
    "print( \"P Value = \", res.pvalue )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value =  2.3092779454937647e-56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=-0.0023411751649873953, intercept=289.75174934781086, rvalue=-0.1327155918375282, pvalue=2.3092779454937647e-56, stderr=0.00014734011317510797)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "res = scipy.stats.linregress(loss_plot[0], loss_plot[1])\n",
    "print( \"P Value = \", res.pvalue )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
